{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fceb64d2-312d-410d-94bf-458a541c1d4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (2.32.4)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting selenium\n",
      "  Using cached selenium-4.34.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting webdriver-manager\n",
      "  Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting fuzzywuzzy\n",
      "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting python-Levenshtein\n",
      "  Using cached python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from requests) (2025.7.14)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Downloading numpy-2.3.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting trio~=0.30.0 (from selenium)\n",
      "  Using cached trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.12.2 (from selenium)\n",
      "  Using cached trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting typing_extensions~=4.14.0 (from selenium)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from trio~=0.30.0->selenium) (24.3.0)\n",
      "Collecting sortedcontainers (from trio~=0.30.0->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.30.0->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from webdriver-manager) (24.2)\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
      "  Downloading levenshtein-0.27.1-cp311-cp311-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
      "Downloading pandas-2.3.1-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/11.3 MB 4.2 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.4/11.3 MB 4.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/11.3 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.9/11.3 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.3 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.3 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.1/11.3 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.9/11.3 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.2/11.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.7/11.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 3.3 MB/s eta 0:00:00\n",
      "Using cached selenium-4.34.2-py3-none-any.whl (9.4 MB)\n",
      "Using cached trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "Using cached trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.27.1-cp311-cp311-win_amd64.whl (100 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.8/1.6 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.6 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading numpy-2.3.2-cp311-cp311-win_amd64.whl (13.1 MB)\n",
      "   ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/13.1 MB 2.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.6/13.1 MB 2.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.1/13.1 MB 2.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.6/13.1 MB 2.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.1/13.1 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.7/13.1 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.2/13.1 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.7/13.1 MB 2.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.2/13.1 MB 2.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.8/13.1 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.3/13.1 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.8/13.1 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.3/13.1 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.6/13.1 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.1/13.1 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 8.7/13.1 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.2/13.1 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.0/13.1 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.5/13.1 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 11.0/13.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/13.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.1/13.1 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.6/13.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.1/13.1 MB 2.5 MB/s eta 0:00:00\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, pytz, fuzzywuzzy, wsproto, tzdata, typing_extensions, rapidfuzz, python-dotenv, outcome, numpy, webdriver-manager, trio, pandas, Levenshtein, trio-websocket, python-Levenshtein, selenium\n",
      "\n",
      "   -- -------------------------------------  1/17 [pytz]\n",
      "   -- -------------------------------------  1/17 [pytz]\n",
      "   -- -------------------------------------  1/17 [pytz]\n",
      "   -- -------------------------------------  1/17 [pytz]\n",
      "   -- -------------------------------------  1/17 [pytz]\n",
      "   -- -------------------------------------  1/17 [pytz]\n",
      "   -- -------------------------------------  1/17 [pytz]\n",
      "   ---- -----------------------------------  2/17 [fuzzywuzzy]\n",
      "   ------- --------------------------------  3/17 [wsproto]\n",
      "   --------- ------------------------------  4/17 [tzdata]\n",
      "   --------- ------------------------------  4/17 [tzdata]\n",
      "   --------- ------------------------------  4/17 [tzdata]\n",
      "   --------- ------------------------------  4/17 [tzdata]\n",
      "   --------- ------------------------------  4/17 [tzdata]\n",
      "  Attempting uninstall: typing_extensions\n",
      "   --------- ------------------------------  4/17 [tzdata]\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "   --------- ------------------------------  4/17 [tzdata]\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "   --------- ------------------------------  4/17 [tzdata]\n",
      "   ----------- ----------------------------  5/17 [typing_extensions]\n",
      "   ----------- ----------------------------  5/17 [typing_extensions]\n",
      "   ----------- ----------------------------  5/17 [typing_extensions]\n",
      "   ----------- ----------------------------  5/17 [typing_extensions]\n",
      "   ----------- ----------------------------  5/17 [typing_extensions]\n",
      "   ----------- ----------------------------  5/17 [typing_extensions]\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "   ----------- ----------------------------  5/17 [typing_extensions]\n",
      "   ----------- ----------------------------  5/17 [typing_extensions]\n",
      "   -------------- -------------------------  6/17 [rapidfuzz]\n",
      "   -------------- -------------------------  6/17 [rapidfuzz]\n",
      "   -------------- -------------------------  6/17 [rapidfuzz]\n",
      "   -------------- -------------------------  6/17 [rapidfuzz]\n",
      "   ---------------- -----------------------  7/17 [python-dotenv]\n",
      "   ---------------- -----------------------  7/17 [python-dotenv]\n",
      "   ------------------ ---------------------  8/17 [outcome]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   --------------------- ------------------  9/17 [numpy]\n",
      "   ----------------------- ---------------- 10/17 [webdriver-manager]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ------------------------- -------------- 11/17 [trio]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   -------------------------------- ------- 14/17 [trio-websocket]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ------------------------------------- -- 16/17 [selenium]\n",
      "   ---------------------------------------- 17/17 [selenium]\n",
      "\n",
      "Successfully installed Levenshtein-0.27.1 fuzzywuzzy-0.18.0 numpy-2.3.2 outcome-1.3.0.post0 pandas-2.3.1 python-Levenshtein-0.27.1 python-dotenv-1.1.1 pytz-2025.2 rapidfuzz-3.13.0 selenium-4.34.2 sortedcontainers-2.4.0 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.14.1 tzdata-2025.2 webdriver-manager-4.0.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install requests pandas selenium webdriver-manager fuzzywuzzy python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "255b5643-553e-4608-baae-ddb2cbc1f151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google\n",
      "  Downloading google-3.0.0-py2.py3-none-any.whl.metadata (627 bytes)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from google) (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from beautifulsoup4->google) (2.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sumair's pc\\desktop\\client_finder\\.conda\\lib\\site-packages (from beautifulsoup4->google) (4.14.1)\n",
      "Downloading google-3.0.0-py2.py3-none-any.whl (45 kB)\n",
      "Installing collected packages: google\n",
      "Successfully installed google-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89671532-922a-4d81-b983-01c9a4e63623",
   "metadata": {},
   "source": [
    "Business Lead Generation and Email Scraping\n",
    "This notebook scrapes business details from Yelp, detects websites using Yelp and Google Search, categorizes businesses into those with and without websites, and extracts emails from Facebook pages and business websites. It generates CSVs for businesses with and without websites and prepares data for cold emailing with tailored service offers (website development or chatbot integration).\n",
    "Dependencies:\n",
    "pip install requests pandas selenium webdriver-manager fuzzywuzzy python-Levenshtein beautifulsoup4 googlesearch-python\n",
    "\n",
    "Requirements:\n",
    "\n",
    "A valid Yelp API key (replace API_KEY in the code).\n",
    "Chrome WebDriver (automatically handled by webdriver-manager).\n",
    "Manual Facebook login for email scraping.\n",
    "Optional: Hunter.io API key for improved email extraction (commented out).\n",
    "\n",
    "Outputs:\n",
    "\n",
    "businesses_with_websites.csv: Businesses with detected websites.\n",
    "businesses_without_websites.csv: Businesses without websites.\n",
    "final_leads.csv: All businesses with emails and service offers.\n",
    "\n",
    "Compliance:\n",
    "\n",
    "Ensure compliance with Yelp and Facebook terms of service.\n",
    "Follow CAN-SPAM Act or GDPR for cold emailing (include unsubscribe links, verify emails).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb0a4ca-9d19-476d-a331-d33027f2a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from fuzzywuzzy import fuzz\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "\n",
    "# Yelp API Key\n",
    "API_KEY = '8xEkMW9G-MyNjsVSh36yj6pvjmffoSnxl_XlARrk5UyHZv1IeKq65LYTMftgTLBPqqzfa8SVrK1F-fikdMjkwzkNmq9uc8A5vhO7W3iA8DaOhWXIfzwkijLkVnVyaHYx'\n",
    "HEADERS = {'Authorization': f'Bearer {API_KEY}'}\n",
    "\n",
    "# Optional: Hunter.io API Key (uncomment if available)\n",
    "# HUNTER_API_KEY = 'your_hunter_api_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f4a9bde-c612-40f6-bd2e-c452aec02a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_yelp(term, zip_code, limit=50):\n",
    "    \"\"\"Search Yelp for businesses by term and zip code.\"\"\"\n",
    "    url = 'https://api.yelp.com/v3/businesses/search'\n",
    "    params = {\n",
    "        'term': term,\n",
    "        'location': zip_code,\n",
    "        'limit': limit\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json().get('businesses', [])\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"❌ Error searching Yelp: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f68f1ebe-7bd7-4a83-9742-85f3493d8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_website(url):\n",
    "    \"\"\"Check if a website URL is valid.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        return response.status_code == 200\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def find_website(business_name, address):\n",
    "    \"\"\"Search Google for the business website.\"\"\"\n",
    "    query = f\"{business_name} {address} official website\"\n",
    "    try:\n",
    "        for url in search(query, num_results=5):\n",
    "            if 'yelp.com' not in url and 'facebook.com' not in url:\n",
    "                return url if check_website(url) else ''\n",
    "        return ''\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error searching Google for website: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd0c3187-7f9b-468b-acce-d07e0e07d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_businesses(businesses):\n",
    "    \"\"\"Process Yelp businesses, detect websites, and categorize them.\"\"\"\n",
    "    businesses_with_websites = []\n",
    "    businesses_without_websites = []\n",
    "    \n",
    "    for b in businesses:\n",
    "        # Check Yelp for website (avoid Yelp URLs)\n",
    "        website = b.get('url', '') if not b.get('url', '').lower().startswith('https://www.yelp.com') else ''\n",
    "        \n",
    "        # If no website found, try Google Search\n",
    "        if not website:\n",
    "            website = find_website(b.get('name', ''), \", \".join(b['location'].get('display_address', [])))\n",
    "        \n",
    "        business_data = {\n",
    "            'Name': b.get('name', ''),\n",
    "            'Phone': b.get('display_phone', ''),\n",
    "            'Address': \", \".join(b['location'].get('display_address', [])),\n",
    "            'Category': \", \".join([cat['title'] for cat in b.get('categories', [])]),\n",
    "            'Website': website,\n",
    "            'Source': 'Yelp'\n",
    "        }\n",
    "        \n",
    "        # Categorize based on website presence\n",
    "        if business_data['Website']:\n",
    "            businesses_with_websites.append(business_data)\n",
    "        else:\n",
    "            businesses_without_websites.append(business_data)\n",
    "    \n",
    "    return businesses_with_websites, businesses_without_websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3362af7-d4db-4e30-a4eb-4852e46aa666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(businesses, filename):\n",
    "    \"\"\"Save business data to a CSV file.\"\"\"\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['Name', 'Phone', 'Address', 'Category', 'Website', 'Source'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(businesses)\n",
    "    print(f\"✅ Saved {len(businesses)} leads to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ace9ce76-c666-48b1-903c-0f422ab33839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_driver():\n",
    "    \"\"\"Initialize Chrome WebDriver with options.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99fef752-775f-492c-9bc5-92b838d3e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_facebook(driver, business_name):\n",
    "    \"\"\"Search Facebook for business pages by name.\"\"\"\n",
    "    search_url = f\"https://www.facebook.com/search/pages?q={business_name.replace(' ', '%20')}\"\n",
    "    try:\n",
    "        driver.get(search_url)\n",
    "        time.sleep(6)\n",
    "        links = driver.find_elements(By.XPATH, \"//a[@href and @role='link']\")\n",
    "        valid_links = [link.get_attribute(\"href\") for link in links if link.get_attribute(\"href\") and \"facebook.com\" in link.get_attribute(\"href\") and not any(x in link.get_attribute(\"href\") for x in [\"/search/\", \"/profile.php\", \"/people/\"])]\n",
    "        return valid_links[:5]  # Limit to top 5 to avoid excessive scraping\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error searching Facebook: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e15ab3f-2d12-4fe4-99a3-c574a592ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_address(driver, target_address, page_url):\n",
    "    \"\"\"Validate Facebook page by matching address with fuzzy matching.\"\"\"\n",
    "    try:\n",
    "        driver.get(page_url)\n",
    "        time.sleep(6)\n",
    "        page_text = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "        score = fuzz.token_set_ratio(target_address.lower(), page_text.lower())\n",
    "        return score >= 70  # Adjustable threshold\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error matching address for {page_url}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "520a50b4-5dbf-4190-b158-638cdcedd253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_facebook(driver):\n",
    "    \"\"\"Extract email from a Facebook page using regex.\"\"\"\n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight / 2);\")\n",
    "        time.sleep(4)\n",
    "        text = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "        emails = re.findall(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", text)\n",
    "        return emails[0] if emails else \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error extracting email from Facebook: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "696e3631-18a3-4e8a-88b9-5c00d30870d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_website(url):\n",
    "    \"\"\"Extract email from a business website using BeautifulSoup.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        emails = re.findall(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", text)\n",
    "        return emails[0] if emails else \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error extracting email from website {url}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5aa89bbf-d458-4540-83f4-37ee0495329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_hunter(business_name, website):\n",
    "    \"\"\"Placeholder for Hunter.io email extraction (requires API key).\"\"\"\n",
    "    # Uncomment and add your Hunter.io API key to use\n",
    "    # url = f\"https://api.hunter.io/v2/domain-search?domain={website}&api_key={HUNTER_API_KEY}\"\n",
    "    # try:\n",
    "    #     response = requests.get(url)\n",
    "    #     response.raise_for_status()\n",
    "    #     data = response.json()\n",
    "    #     return data.get('data', {}).get('emails', [{}])[0].get('value', '')\n",
    "    # except Exception as e:\n",
    "    #     print(f\"⚠️ Error with Hunter.io for {business_name}: {e}\")\n",
    "    #     return \"\"\n",
    "    return \"\"  # Return empty string if not using Hunter.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c043d36f-04d7-4110-8661-d4a1db18e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_emails(input_csv, output_csv):\n",
    "    \"\"\"Scrape emails from Facebook and websites for businesses in the input CSV.\"\"\"\n",
    "    businesses = pd.read_csv(input_csv).to_dict('records')\n",
    "    driver = create_driver()\n",
    "    \n",
    "    print(\"🔐 Please log in to Facebook manually...\")\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    input(\"✅ Press Enter after logging into Facebook...\")\n",
    "    \n",
    "    results = []\n",
    "    for i, business in enumerate(businesses):\n",
    "        name = business['Name']\n",
    "        address = business['Address']\n",
    "        website = business.get('Website', '')\n",
    "        print(f\"🔍 [{i+1}] Processing: {name} - {address}\")\n",
    "        \n",
    "        # Try extracting email\n",
    "        matched_email = \"\"\n",
    "        \n",
    "        # Step 1: Try website (if available)\n",
    "        if website:\n",
    "            matched_email = extract_email_website(website)\n",
    "            if matched_email:\n",
    "                print(f\"📧 Email Found (Website): {matched_email}\")\n",
    "        \n",
    "        # Step 2: Try Facebook if no email from website\n",
    "        if not matched_email:\n",
    "            fb_links = search_facebook(driver, name)\n",
    "            for link in fb_links:\n",
    "                if match_address(driver, address, link):\n",
    "                    matched_email = extract_email_facebook(driver)\n",
    "                    if matched_email:\n",
    "                        print(f\"📧 Email Found (Facebook): {matched_email}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"⚠️ No email on matched Facebook page\")\n",
    "                time.sleep(2)  # Avoid rate limiting\n",
    "        \n",
    "        # Step 3: Try Hunter.io (optional, uncomment if API key available)\n",
    "        # if not matched_email and website:\n",
    "        #     matched_email = get_email_hunter(name, website)\n",
    "        #     if matched_email:\n",
    "        #         print(f\"📧 Email Found (Hunter.io): {matched_email}\")\n",
    "        \n",
    "        if not matched_email:\n",
    "            print(\"❌ No matching email found\")\n",
    "        \n",
    "        results.append({\n",
    "            \"Name\": name,\n",
    "            \"Phone\": business.get('Phone', ''),\n",
    "            \"Address\": address,\n",
    "            \"Category\": business.get('Category', ''),\n",
    "            \"Website\": website,\n",
    "            \"Email\": matched_email,\n",
    "            \"Source\": business.get('Source', 'Yelp'),\n",
    "            \"Service Offered\": \"Chatbot Integration\" if website else \"Website Development\"\n",
    "        })\n",
    "        time.sleep(5)  # Avoid rate limiting\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    # Save results to CSV\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"Name\", \"Phone\", \"Address\", \"Category\", \"Website\", \"Email\", \"Source\", \"Service Offered\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "    print(f\"✅ Done! Leads saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f807ae0-9cef-44b2-ba84-3ce06eeac05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "def send_cold_email(to_email, business_name, service_offered, sender_email, sender_password):\n",
    "    \"\"\"Send a cold email with a tailored service offer.\"\"\"\n",
    "    if not to_email:\n",
    "        print(f\"❌ No email provided for {business_name}\")\n",
    "        return\n",
    "    \n",
    "    if service_offered == \"Website Development\":\n",
    "        subject = \"Boost Your Business with a Professional Website\"\n",
    "        body = f\"\"\"Hi {business_name},\n",
    "\n",
    "We noticed your business doesn’t have a website. Our team specializes in creating affordable, high-quality websites to help you attract more customers.\n",
    "\n",
    "Reply to schedule a free consultation!\n",
    "Best,\n",
    "[Your Name]\n",
    "Unsubscribe: [Your Unsubscribe Link]\n",
    "\"\"\"\n",
    "    else:\n",
    "        subject = \"Enhance Your Website with a Smart Chatbot\"\n",
    "        body = f\"\"\"Hi {business_name},\n",
    "\n",
    "Your website looks great! Want to engage visitors 24/7? We offer chatbot integration to answer customer queries and boost conversions.\n",
    "\n",
    "Reply to learn more!\n",
    "Best,\n",
    "[Your Name]\n",
    "Unsubscribe: [Your Unsubscribe Link]\n",
    "\"\"\"\n",
    "    \n",
    "    msg = MIMEText(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = to_email\n",
    "    \n",
    "    try:\n",
    "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, sender_password)\n",
    "            server.send_message(msg)\n",
    "            print(f\"📧 Email sent to {to_email}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error sending email to {to_email}: {e}\")\n",
    "\n",
    "# Example usage (uncomment to test, replace with your email and app password)\n",
    "# sender_email = \"your_email@gmail.com\"\n",
    "# sender_password = \"your_app_password\"\n",
    "# df = pd.read_csv(\"final_leads.csv\")\n",
    "# for _, row in df.iterrows():\n",
    "#     send_cold_email(row['Email'], row['Name'], row['Service Offered'], sender_email, sender_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f76bd880-2c7c-4840-8689-45462de56080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter ZIP Code (e.g., 90223):  79707\n",
      "Enter business type (e.g., bakery, plumber):  Doctor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "⚠️ Error searching Google for website: search() got an unexpected keyword argument 'num_results'\n",
      "✅ Saved 0 leads to businesses_with_websites.csv\n",
      "✅ Saved 50 leads to businesses_without_websites.csv\n",
      "✅ Saved 50 leads to all_businesses.csv\n",
      "🔐 Please log in to Facebook manually...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "✅ Press Enter after logging into Facebook... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 [1] Processing: Patel Raj R MD - 4214 Andrews Hwy, Ste 100B, Midland, TX 79703\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [2] Processing: Midland Primary Care - 1300 W Wall St, Midland, TX 79701\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [3] Processing: JOYCE ALASE, MD - 207 Tradewinds Blvd C, Ste C, Midland, TX 79706\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [4] Processing: Patel Pk MD - 4214 Andrews Hwy, Ste 303, Midland, TX 79703\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [5] Processing: Shylesh R Ganta, MD - 3401 Greenbriar, Ste 100, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [6] Processing: Preferred Medical Center - 1200 Andrews Hwy, Midland, TX 79701\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [7] Processing: Emily Baker, DO - Midland Health - 3415 N Loop 250 W, Bldg 4, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [8] Processing: Briarwood Clinic - 5000 Briarwood Ave, Ste 203, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [9] Processing: Welsh James MD - 4214 Andrews Hwy, Ste 303, Midland, TX 79703\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [10] Processing: Vikram Vadyala, MD - 2002 N Midland Dr, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [11] Processing: Midland Women's Clinic - 2500 W Illinois Ave, Ste 100, Midland, TX 79703\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [12] Processing: Garcia Juan MD - 1802 W Wall St, Midland, TX 79701\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [13] Processing: Bellisimo Salon - 4519 N Garfield St, # 9, Midland, TX 79705\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [14] Processing: Salcido, Francisco MD, DABFM - 710 E 6th St, Oddessa, TX 79705\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [15] Processing: WesTex Urgent Care - 6301 Andrews Hwy, Midland, TX 79706\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [16] Processing: Courtyard Family Practice - 4410 N Midkiff Rd, Ste D6, Midland, TX 79705\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [17] Processing: Midland Plastic Surgery Center - 701 Tradewinds Blvd, Ste B, Midland, TX 79706\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [18] Processing: West Texas Foot & Ankle Associates - 1913 Heritage Blvd, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [19] Processing: Bonnie C Carter, MD - 1940 East 42nd St, Medical Center Health System, Odessa, TX 79762\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [20] Processing: Venegas Eric, MD - 5007 Portico Way, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [21] Processing: Evangelion Medical - 15 Smith Rd, Ste 3004, Midland, TX 79705\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [22] Processing: Vital Care Urgent Care - 4400 N Midland Dr, Ste 406A, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [23] Processing: Kids Kare Pediatrics - 5019 Portico Way, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [24] Processing: Suresh Prasad, MD - 403 Pittsburg Ave, Permian Internal Medicine Associates, Odessa, TX 79761\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [25] Processing: Fredrickson Mark MD - 1800 Heritage Blvd, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [26] Processing: SignatureCare Emergency Center - Midland - 5409 W Wadley Ave, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [27] Processing: Complete Care of Midland - 1701 N Loop 250 W, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [28] Processing: Family Care Clinic - 4506 Briarwood Ave, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [29] Processing: MCGEHEE FRANK md - 509 N Garfield St, Midland, TX 79701\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [30] Processing: Pedi Med Center - 5801 W Wadley Ave, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [31] Processing: Ashley Browning, PA-C - Platinum Family Care Clinic, 604 Kent St, Midland, TX 79701\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [32] Processing: Midland Dermatology - 5117 Sunmore Cir, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [33] Processing: ReGen Clinic of West Texas - 801 Tradewinds Blvd, Ste B, Midland, TX 79706\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [34] Processing: Sykes Chiropractic - 900 W Loop 250 N, Ste D, Midland, TX 79705\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [35] Processing: Gameday Men's Health - 4400 Midland Dr, Ste 2200, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [36] Processing: Synergy Integrative Medical Clinic - 5813 W Wadley Ave, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [37] Processing: The Desert Hippie and Company - 2101 W Wadley Ave, Ste 42, Midland, TX 79705\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [38] Processing: Midland Memorial Hospital - 400 Rosalind Redfern Grover Pkwy, Midland, TX 79701\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [39] Processing: Texas Surgical Center - 5609 Deauville Blvd, Midland, TX 79706\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [40] Processing: Premier Family Care - 4801 N Midland Dr, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [41] Processing: Midland Family Physicians PA Business Office - 3620 N Big Spring St, Midland, TX 79705\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [42] Processing: Nabulsi Nefous MD - 5801 W Wadley Ave, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [43] Processing: WesTex Urgent Care - 4705 Briarwood Ave, Ste 200, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [44] Processing: Haritha Bellam, MD - 2301 W Michigan Ave, Midland, TX 79706\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [45] Processing: Permian Psychiatry - 5721 Ridgemont Pl, Midland, TX 79707\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [46] Processing: Regional Perinatal Center - 4911 Andrews Hwy, Ste a, Midland, TX 79703\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [47] Processing: Midland Pediatric Associates - 4214 Mamies Cir, Midland, TX 79705\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [48] Processing: Plum Pediatrics - 807 Tradewinds Blvd, Midland, TX 79706\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [49] Processing: Midland Memorial Hospital - 4214 Andrews Hwy, Midland, TX 79703\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "🔍 [50] Processing: West Texas Orthopedics - 5615 Deauville Blvd, Ste 220, Midland, TX 79706\n",
      "⚠️ Error extracting email from website nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "❌ No matching email found\n",
      "✅ Done! Leads saved to: final_leads.csv\n"
     ]
    }
   ],
   "source": [
    "# Input section\n",
    "zip_code = input(\"Enter ZIP Code (e.g., 90223): \")\n",
    "keyword = input(\"Enter business type (e.g., bakery, plumber): \")\n",
    "\n",
    "# Scrape Yelp data\n",
    "raw_results = search_yelp(keyword, zip_code)\n",
    "businesses_with_websites, businesses_without_websites = process_businesses(raw_results)\n",
    "\n",
    "# Save to separate CSVs\n",
    "save_to_csv(businesses_with_websites, \"businesses_with_websites.csv\")\n",
    "save_to_csv(businesses_without_websites, \"businesses_without_websites.csv\")\n",
    "\n",
    "# Scrape emails for all businesses\n",
    "all_businesses = businesses_with_websites + businesses_without_websites\n",
    "if all_businesses:\n",
    "    save_to_csv(all_businesses, \"all_businesses.csv\")  # Temporary CSV for email scraping\n",
    "    scrape_emails(\"all_businesses.csv\", \"final_leads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8166fa6-a235-48d3-85c9-2bd6bab581c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359cc00-ba7d-496d-9aba-5bc001ae71e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea324a6d-fc9c-4134-92bb-86b0c47d6e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e339a-0684-4cd7-811c-8825660e4214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc4c93-8db6-4446-8609-deb547164dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3627e-6740-4349-b409-b065b24d9a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483cde6-eca2-4328-b6cf-ec3784ff4516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda]",
   "language": "python",
   "name": "conda-env-.conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
